{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "from uszipcode import SearchEngine\n",
    "search = SearchEngine(simple_zipcode = True)\n",
    "import us_state_abbrev\n",
    "statedict = us_state_abbrev.us_state_abbrev\n",
    "from pyts.preprocessing import InterpolationImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zillow Rental Index Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zori = pd.read_csv('./data/Zip_ZORI_AllHomesPlusMultifamily_SSA.csv')\n",
    "zori = pd.concat([zori['RegionName'], zori.iloc[:, 4:]], axis = 1)\n",
    "zori['County'] = zori['RegionName'].apply(lambda zipcode: search.by_zipcode(zipcode).values()[5][:-7]\\\n",
    "                                              if search.by_zipcode(zipcode).values()[5] is not None else 'NA')\n",
    "zori['State'] = zori['RegionName'].apply(lambda zipcode: search.by_zipcode(zipcode).values()[6]\\\n",
    "                                              if search.by_zipcode(zipcode).values()[6] is not None else 'NA')\n",
    "zori = pd.concat([zori[['RegionName', 'County', 'State']], zori.iloc[:, 2:-3]], axis = 1)\n",
    "zori.columns = zori.columns.str.replace('RegionName', 'ZipCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = zori.iloc[:, :3].iloc[np.arange(zori.shape[0]).repeat(zori.iloc[:, 3:].shape[1])].reset_index().drop('index',\n",
    "                                                                                                             axis = 1)\n",
    "temp2 = pd.melt(zori.iloc[:, 3:].T.reset_index(), id_vars = 'index').drop('variable', axis = 1)\n",
    "temp2.columns = ['Date', 'ZORI']\n",
    "temp2['Year'] = temp2['Date'].map(lambda date: int(date[:4]))\n",
    "temp2['Month'] = temp2['Date'].map(lambda date: int(date[-2:]))\n",
    "temp2['Year_Month'] = temp2['Year'].map(str) + '_' + temp2['Month'].map(str)\n",
    "temp2.drop('Date', axis = 1, inplace = True)\n",
    "zori = pd.concat([temp1, temp2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "zori.to_csv('./data/cleandata/clean_zori.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FHFI (Home Price Index) HPI Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_excel('./data/HPI_AT_BDL_ZIP5.xlsx', skiprows = 6)\n",
    "temp = temp[temp['Year'] >= 2010]\n",
    "temp = temp[['Five-Digit ZIP Code', 'Year', 'HPI with 2000 base']]\n",
    "temp.columns = ['ZipCode', 'Year', 'HPI']\n",
    "temp = temp[temp['HPI'] != '.']\n",
    "temp['HPI'] = temp['HPI'].map(float)\n",
    "temp = temp[temp['ZipCode'].isin(temp.groupby('ZipCode').count()['HPI'][temp.groupby('ZipCode').count()['HPI'] >= 8].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = pd.DataFrame({'ZipCode': pd.unique(temp['ZipCode']).repeat(10), \n",
    "                      'Year': list(np.arange(2010, temp['Year'].max() + 1)) * len(pd.unique(temp['ZipCode']))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(temp2, temp, on = ['ZipCode', 'Year'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zipcode, df in temp.groupby('ZipCode'):\n",
    "    if df['HPI'].isnull().sum() == 0:\n",
    "        continue\n",
    "    else:\n",
    "        imputer = InterpolationImputer()\n",
    "        df['HPI'] = imputer.transform([list(df[['HPI']].reset_index()['index']), \n",
    "                                       list(df[['HPI']].reset_index()['HPI'])])[1]\n",
    "        temp.loc[temp['ZipCode'] == zipcode, 'HPI'] = df['HPI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearmonth = pd.DataFrame({'Year': np.arange(temp['Year'].min(), temp['Year'].max() + 1).repeat(12),\n",
    "                          'Month': list(np.arange(1, 13)) * (temp['Year'].max() - temp['Year'].min() + 1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpi = pd.merge(temp, yearmonth, on = 'Year')\n",
    "hpi['Year_Month'] = hpi['Year'].map(str) + '_' + hpi['Month'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpi = hpi[['ZipCode', 'Year', 'Month', 'Year_Month', 'HPI']]\n",
    "hpi.to_csv('./data/cleandata/clean_hpi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zillow Home Value Index Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhvi = pd.read_csv('./data/Zip_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_mon.csv')\n",
    "zhvi['CountyName'] = zhvi['CountyName'].map(lambda county: county[:-7] if county[-6:] == 'County' else county)\n",
    "zhvi = pd.concat([zhvi[['RegionName', 'CountyName', 'State']], zhvi.iloc[:, 9:]], axis = 1)\n",
    "zhvi.columns = zhvi.columns.str.replace('RegionName', 'ZipCode')\n",
    "zhvi.columns = zhvi.columns.str.replace('CountyName', 'County')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = zhvi.iloc[:, :3].iloc[np.arange(zhvi.shape[0]).repeat(zhvi.iloc[:, 3:].shape[1])].reset_index().drop('index',\n",
    "                                                                                                             axis = 1)\n",
    "temp2 = pd.melt(zhvi.iloc[:, 3:].T.reset_index(), id_vars = 'index').drop('variable', axis = 1)\n",
    "temp2.columns = ['Date', 'ZHVI']\n",
    "temp2['Year'] = temp2['Date'].map(lambda date: int(date[:4]))\n",
    "temp2['Month'] = temp2['Date'].map(lambda date: int(date[5:7]))\n",
    "temp2['Year_Month'] = temp2['Year'].map(str) + '_' + temp2['Month'].map(str)\n",
    "temp2.drop('Date', axis = 1, inplace = True)\n",
    "zhvi = pd.concat([temp1, temp2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3 = zhvi.groupby('ZipCode').count()['ZHVI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhvi = zhvi[zhvi['ZipCode'].isin(temp3[~temp3.where(temp3 >= 200).isnull()].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for zipcode, df in zhvi.groupby('ZipCode'):\n",
    "    if df['ZHVI'].isnull().sum() == 0:\n",
    "        continue\n",
    "    else:\n",
    "        imputer = InterpolationImputer()\n",
    "        df['ZHVI'] = imputer.transform([list(df[['ZHVI']].reset_index()['index']), \n",
    "                                        list(df[['ZHVI']].reset_index()['ZHVI'])])[1]\n",
    "        zhvi.loc[zhvi['ZipCode'] == zipcode, 'ZHVI'] = df['ZHVI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation produces some negative values but for periods before 2000, which is not important for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhvi.to_csv('./data/cleandata/clean_zhvi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Air Quality Index Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def airqcompiler(start, end):\n",
    "    \"\"\"Compiles air quality index csv files from 'start' to 'end' into 1 clean dataframe\"\"\"\n",
    "    final = pd.DataFrame()\n",
    "    for i in range(start, end + 1):\n",
    "        temp = pd.read_csv(f'./data/daily_aqi_by_county_{i}/daily_aqi_by_county_{i}.csv')[['county Name', 'State Name',\n",
    "                                                                                    'Date', 'AQI']]\n",
    "        temp['State Name'] = temp['State Name'].apply(lambda state: statedict.get(state))\n",
    "        temp.columns = temp.columns.str.replace('county Name', 'County')\n",
    "        temp.columns = temp.columns.str.replace('State Name', 'State')\n",
    "        temp['Date'] = temp['Date'].apply(lambda date: pd.to_datetime(date, format = '%Y-%m-%d'))\n",
    "        temp['Month'] = temp['Date'].apply(lambda date: date.month)\n",
    "        temp['Year'] = temp['Date'].apply(lambda date: date.year)\n",
    "        temp = temp.groupby(['County', 'State', 'Year', 'Month']).mean().reset_index()\n",
    "        \n",
    "        time_df = pd.DataFrame({'Year': np.array(i).repeat(len(temp.groupby(['County', 'State']).count().index) * 12), \n",
    "                                'Month': list(np.arange(1, 13)) * len(temp.groupby(['County', 'State']).count().index)})\n",
    "        time_df['County'] = sum([[county] * 12 for county, state in temp.groupby(['County', 'State']).count().index], [])\n",
    "        time_df['State'] = sum([[state] * 12 for county, state in temp.groupby(['County', 'State']).count().index], [])\n",
    "        \n",
    "        temp = pd.merge(time_df, temp, on = ['Year', 'Month', 'County', 'State'], how = 'left')\n",
    "        temp['Year_Month'] = temp['Year'].map(str) + '_' + temp['Month'].map(str)\n",
    "        final = pd.concat([final, temp], axis = 0)\n",
    "        print(f'Finished compiling year {i}.')\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished compiling year 2013.\n",
      "Finished compiling year 2014.\n",
      "Finished compiling year 2015.\n",
      "Finished compiling year 2016.\n",
      "Finished compiling year 2017.\n",
      "Finished compiling year 2018.\n",
      "Finished compiling year 2019.\n",
      "Finished compiling year 2020.\n"
     ]
    }
   ],
   "source": [
    "airq = airqcompiler(2013, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = airq.groupby(['County', 'State']).count()['AQI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = pd.DataFrame({'County': [x[0] for x in temp[~temp.where(temp >= 75).isnull()].index], \n",
    "                      'State': [x[1] for x in temp[~temp.where(temp >= 75).isnull()].index]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "airq = pd.merge(airq, temp2, on = ['County', 'State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (county, state), df in airq.groupby(['County', 'State']):\n",
    "    if df['AQI'].isnull().sum() == 0:\n",
    "        continue\n",
    "    else:\n",
    "        imputer = InterpolationImputer()\n",
    "        df['AQI'] = imputer.transform([list(df[['AQI']].reset_index()['index']), \n",
    "                                        list(df[['AQI']].reset_index()['AQI'])])[1]\n",
    "        airq.loc[(airq['County'] == county) & (airq['State'] == state), 'AQI'] = df['AQI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "airq.loc[airq['AQI'] < 0, 'AQI'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "airq.to_csv('./data/cleandata/clean_airq.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popcompiler(start, end):\n",
    "    \"\"\"Compiles population csv files from 'start' to 'end' into 1 clean dataframe\"\"\"\n",
    "    final = pd.DataFrame()\n",
    "    for i in range(start, end + 1):\n",
    "        temp = pd.read_csv(f'./data/productDownload_2020-12-09T144241/ACSDT1Y{i}.B01003_data.csv', header = 1)\n",
    "        temp = temp[['Geographic Area Name', 'Estimate!!Total']]\n",
    "        temp.columns = ['County', 'Population']\n",
    "        temp['State'] = temp['County'].apply(lambda county: statedict.get(county[(county.find(',') + 2):]))\n",
    "        temp['County'] = temp['County'].apply(lambda county: county[:(county.find('County') - 1)] if 'County'\\\n",
    "                                              in county else (county[:(county.find('Municipio') - 1)] if 'Municipio'\\\n",
    "                                                             in county else county))\n",
    "        temp['Year'] = [i for x in range(temp.shape[0])]\n",
    "        final = pd.concat([final, temp], axis = 0)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = popcompiler(2011, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.merge(temp, yearmonth, on = 'Year')\n",
    "population['Year_Month'] = population['Year'].map(str) + '_' + population['Month'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.to_csv('./data/cleandata/clean_population.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the unemployment dataframe\n",
    "unemployment = pd.read_csv('./data/US_unemployment.csv', index_col = 0)\n",
    "unemployment = unemployment[~unemployment['County'].isnull()]\n",
    "unemployment['County'] = unemployment['County'] + ', ' + unemployment['State']\n",
    "unemployment.drop('State', axis = 1, inplace = True)\n",
    "unemployment = unemployment.T\n",
    "unemployment.columns = unemployment.iloc[0, :]\n",
    "unemployment = unemployment.iloc[1:, :]\n",
    "unemployment.reset_index(inplace = True)\n",
    "unemployment.columns.name = None\n",
    "unemployment['Year'] = unemployment['index'].map(lambda year: int(year[-4:]))\n",
    "unemployment = pd.concat([unemployment, pd.DataFrame(list(range(1, 13)) * int(unemployment.shape[0] / 12),\n",
    "                                                     columns = ['Month'])], axis = 1)\n",
    "unemployment['Year_Month'] = unemployment['Year'].map(str) + '_' + unemployment['Month'].map(str)\n",
    "unemployment.drop('index', axis = 1, inplace = True)\n",
    "temp = pd.DataFrame()\n",
    "for county in unemployment.columns[:-3].to_list():\n",
    "    temp2 = unemployment[[county, 'Year', 'Month', 'Year_Month']]\n",
    "    temp2 = temp2.assign(County = temp2.columns[0])\n",
    "    temp2.columns = ['Unemployment', 'Year', 'Month', 'Year_Month', 'County']\n",
    "    temp = pd.concat([temp, temp2], axis = 0)\n",
    "unemployment = temp\n",
    "unemployment['State'] = unemployment['County'].map(lambda county: county[-2:])\n",
    "unemployment['County'] = unemployment['County'].map(lambda county: county[:county.find(',')])\n",
    "unemployment['Unemployment'] = unemployment['Unemployment'].map(lambda x: str(x)[:str(x).find('(')]\\\n",
    "                                                                if str(x).find('(') != -1 else str(x))\n",
    "unemployment['Unemployment'] = unemployment['Unemployment'].map(lambda x: float(x) if (x != ' ')\\\n",
    "                                                                & (x != 'No Data Available ') else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = unemployment.groupby(['County', 'State']).count()['Unemployment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = pd.DataFrame({'County': [x[0] for x in temp[~temp.where(temp >= 75).isnull()].index], \n",
    "                      'State': [x[1] for x in temp[~temp.where(temp >= 75).isnull()].index]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = pd.merge(unemployment, temp2, on = ['County', 'State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.to_csv('./data/cleandata/clean_unemployment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "education = pd.read_csv('./data/US_education.csv').drop('Unnamed: 0', axis = 1)\n",
    "education = education[education['County'] != 'United States']\n",
    "education['County'] = education['County'].apply(lambda county: county[:(county.find('County') - 1)] if 'County'\\\n",
    "                                              in county else (county[:(county.find('Municipio') - 1)] if 'Municipio'\\\n",
    "                                                             in county else county))\n",
    "education.loc[education['State'] == 'District of Columbia', 'State'] = 'District Of Columbia'\n",
    "education['State'] = education['State'].map(lambda state: statedict.get(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "education2 = pd.read_csv('./data/US_education_update.csv')\n",
    "education2 = education2[education2['County'] != 'United States']\n",
    "education2 = education2[education2['Year'] == 2012]\n",
    "education2['County'] = education2['County'].apply(lambda county: county[:(county.find('County') - 1)] if 'County'\\\n",
    "                                                  in county else (county[:(county.find('Municipio') - 1)] if 'Municipio'\\\n",
    "                                                                 in county else county))\n",
    "education2.loc[education2['State'] == 'District of Columbia', 'State'] = 'District Of Columbia'\n",
    "education2['State'] = education2['State'].map(lambda state: statedict.get(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "education = pd.concat([education2, education], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "education = pd.merge(education, yearmonth, on = 'Year')\n",
    "education['Year_Month'] = education['Year'].map(str) + '_' + education['Month'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "education.to_csv('./data/cleandata/clean_education.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permits Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "permits = pd.read_csv('./data/US_permits.csv').drop('Unnamed: 0', axis = 1)\n",
    "month_to_number = {'January' : 1, 'February' : 2, 'March' : 3, 'April' : 4, 'May' : 5, 'June' : 6, 'July' : 7, \n",
    "                   'August' : 8, 'September' : 9, 'October' : 10, 'November' : 11, 'December' : 12}\n",
    "permits['Month'] = permits['Month'].map(lambda month: month_to_number.get(month))\n",
    "permits['Year_Month'] = permits['Year'].map(str) + '_' + permits['Month'].map(str)\n",
    "temp = permits[permits['State'] == 'MN'].groupby(['Year', 'Month', 'Year_Month', 'State']).sum().reset_index()\n",
    "permits = permits[permits['State'] != 'MN']\n",
    "permits = pd.concat([permits, temp], axis = 0)\n",
    "permits.reset_index().drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "permits.to_csv('./data/cleandata/clean_permits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median Income and Total Households Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "IandH = pd.read_csv('./data/income_and_households.csv').drop('Unnamed: 0', axis = 1)\n",
    "IandH['County'] = IandH['County'].apply(lambda county: county[:(county.find('County') - 1)] if 'County'\\\n",
    "                                        in county else (county[:(county.find('Municipio') - 1)] if 'Municipio'\\\n",
    "                                                        in county else county))\n",
    "IandH['Year_Month'] = IandH['Year'].map(str) + '_' + IandH['Month'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "IandH.to_csv('./data/cleandata/clean_IandH.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inflation Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "pce = pd.read_excel('./data/underlying-inflation-dashboard-data.xlsx', sheet_name = 'PCE')\n",
    "pce['Year'] = pce['Date'].map(lambda date: date.year)\n",
    "pce['Month'] = pce['Date'].map(lambda date: date.month)\n",
    "pce.drop('Date', axis = 1, inplace = True)\n",
    "pce['Year_Month'] = pce['Year'].map(str) + '_' + pce['Month'].map(str)\n",
    "pce = pce[~pce['PCE'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "pce.to_csv('./data/cleandata/clean_pce.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vacancy Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancy = pd.read_csv('./data/vacancy.csv').drop('Unnamed: 0', axis = 1)\n",
    "vacancy.columns = ['Year', 'County', 'State', 'Rental Vacancy Rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancy = pd.merge(vacancy, yearmonth, on = 'Year')\n",
    "vacancy['Year_Month'] = vacancy['Year'].map(str) + '_' + vacancy['Month'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancy.to_csv('./data/cleandata/clean_vacancy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Openings Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv('./data/modified_jos.csv').drop('Unnamed: 0', axis = 1)[['State', 'Region', 'Year', 'Month', \n",
    "                                                                                  'Job Openings']]\n",
    "jobs = jobs.groupby(['State', 'Year', 'Month']).sum().reset_index()\n",
    "jobs['Year_Month'] = jobs['Year'].map(str) + '_' + jobs['Month'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.to_csv('./data/cleandata/clean_jos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commute and Type of Worker Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_worker = pd.read_csv('./data/commute_white_collar.csv').drop('Unnamed: 0', axis = 1)\n",
    "commute_worker['County'] = commute_worker['County'].apply(lambda county: county[:(county.find('County') - 1)] if 'County'\\\n",
    "                                                  in county else (county[:(county.find('Municipio') - 1)] if 'Municipio'\\\n",
    "                                                                 in county else county))\n",
    "commute_worker.drop('Selfemply', axis = 1, inplace = True)\n",
    "commute_worker.drop('cChange', axis = 1, inplace = True)\n",
    "commute_worker['Year_Month'] = commute_worker['Year'].map(str) + '_' + commute_worker['Month'].map(str)\n",
    "commute_worker = commute_worker[['County', 'state', 'Year', 'Month', 'Year_Month', 'CommuteTime', 'Salwrkr', 'Govwrkr']]\n",
    "commute_worker.columns = ['County', 'State', 'Year', 'Month', 'Year_Month', 'CommuteTime', 'Salwrkr', 'Govwrkr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_worker.to_csv('./data/cleandata/clean_commute_worker.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPI Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapi = pd.read_csv('./data/grapi.csv').drop('Unnamed: 0', axis = 1)\n",
    "grapi['County'] = grapi['County'].apply(lambda county: county[:(county.find('County') - 1)] if 'County'\\\n",
    "                                        in county else (county[:(county.find('Municipio') - 1)] if 'Municipio'\\\n",
    "                                                        in county else county))\n",
    "grapi['Year_Month'] = grapi['Year'].map(str) + '_' + grapi['Month'].map(str)\n",
    "grapi = grapi[['County', 'state', 'Year', 'Month', 'Year_Month', 'GRAPI']]\n",
    "grapi.columns = ['County', 'State', 'Year', 'Month', 'Year_Month', 'GRAPI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapi.to_csv('./data/cleandata/clean_grapi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Density Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_area = pd.read_csv('./data/land_area.csv')\n",
    "land_area['State'] = land_area['State'].map(lambda state: state[1:])\n",
    "population_density = pd.merge(population, land_area, on = ['County', 'State'])\n",
    "population_density['P_Density'] = population_density['Population'] / population_density['Area'] \n",
    "population_density['Year_Month'] = population_density['Year'].map(str) + '_' + population_density['Month'].map(str)\n",
    "population_density = population_density[['County', 'State', 'Year', 'Month', 'Year_Month', 'P_Density']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_density.to_csv('./data/cleandata/clean_population_density.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inequality Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_inequality = pd.read_csv('./data/gini_ineq.csv').drop('Unnamed: 0', axis = 1)\n",
    "income_inequality['County'] = income_inequality['County'].apply(lambda county: county[:(county.find('County') - 1)]\\\n",
    "                                if 'County' in county else (county[:(county.find('Municipio') - 1)] if 'Municipio'\\\n",
    "                                in county else county))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_inequality.to_csv('./data/cleandata/clean_income_inequality.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
